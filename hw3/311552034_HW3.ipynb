{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZQD8NqPhKyBP"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score # Please note that this is the only sklearn function that can be utilized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV1MHt_VTg9f"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a1vkTOD6K5Nj"
      },
      "outputs": [],
      "source": [
        "# Load the train/val/test dataset\n",
        "\n",
        "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
        "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
        "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
        "\n",
        "X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_train = df_train[\"Target\"].to_numpy()\n",
        "\n",
        "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_val = df_val[\"Target\"].to_numpy()\n",
        "\n",
        "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
        "y_test = df_test[\"Target\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MJcktFIuK78Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(800, 7)\n",
            "(800,)\n",
            "(800, 7)\n",
            "(800,)\n",
            "(800, 7)\n",
            "(800,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa3hnJ9sTkvh"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5e_nviB8LAK8"
      },
      "outputs": [],
      "source": [
        "def gini(sequence, sample_weight=None):\n",
        "    information = 0\n",
        "\n",
        "    if sample_weight is not None:\n",
        "        # get sum of sample_weight\n",
        "        weight_sum = sum(sample_weight)\n",
        "        values = np.unique(sequence)\n",
        "\n",
        "        # get the information of each class\n",
        "        for value in values:\n",
        "            idx = [idx for idx, x in enumerate(sequence) if x == value]\n",
        "            count = np.sum(sample_weight[idx])\n",
        "            information += (count / weight_sum)**2\n",
        "\n",
        "    else:\n",
        "        values, counts = np.unique(sequence, return_counts=True)\n",
        "        for count in counts:\n",
        "            information += (count / len(sequence))**2\n",
        "\n",
        "    return 1 - information\n",
        "\n",
        "\n",
        "def entropy(sequence, sample_weight=None):\n",
        "    information = 0\n",
        "\n",
        "    if sample_weight is not None:\n",
        "        # get sum of sample_weight\n",
        "        weight_sum = sum(sample_weight)\n",
        "        values = np.unique(sequence)\n",
        "\n",
        "        # get the information of each class\n",
        "        for value in values:\n",
        "            idx = [idx for idx, x in enumerate(sequence) if x == value]\n",
        "            count = np.sum(sample_weight[idx])\n",
        "            information += -(count / weight_sum) * np.log2(count / weight_sum)\n",
        "\n",
        "    else:\n",
        "        values, counts = np.unique(sequence, return_counts=True)\n",
        "        for count in counts:\n",
        "            information += -(count / len(sequence)) * np.log2(count / len(sequence))\n",
        "\n",
        "    return information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_HJA_108LF_G"
      },
      "outputs": [],
      "source": [
        "class Tree():\n",
        "    \"\"\"\n",
        "        You can add/change any variables/methods to meet your need.\n",
        "    \"\"\"\n",
        "    def __init__( self, feature=None, threshold=None, left=None, right=None, value=None ):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O_vgKCIwLdS0"
      },
      "outputs": [],
      "source": [
        "class DecisionTree():\n",
        "    def __init__(self, criterion='gini', max_depth=None, max_features=None , min_impurity=1e-7, min_samples_split=2):\n",
        "        \n",
        "        \"\"\"\n",
        "            You can add/change any variables/methods to meet your need.\n",
        "        \"\"\"\n",
        "\n",
        "        if criterion == 'gini':\n",
        "            self.criterion = gini\n",
        "        elif criterion == 'entropy':\n",
        "            self.criterion = entropy\n",
        "        \n",
        "        if max_depth is None:\n",
        "            self.max_depth = 1e9\n",
        "        else:\n",
        "            self.max_depth = max_depth\n",
        "\n",
        "        self.importance = {}\n",
        "        self.min_samples_split = min_samples_split  # 若要分裂所需最小 sample 數量\n",
        "        self.min_impurity = min_impurity          # 分裂所需的最小不纯度\n",
        "        self.n_feats = max_features\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y, sample_weight=None):\n",
        "        self.sample_weight = sample_weight\n",
        "        self.importance = {key: 0 for key in range(X.shape[1])}\n",
        "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # stopping criteria\n",
        "        if  depth >= self.max_depth or self.criterion(y) < self.min_impurity or n_samples < self.min_samples_split:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Tree(value=leaf_value)\n",
        "\n",
        "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
        "\n",
        "        # greedily select the best split according to information gain\n",
        "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
        "        if best_feat is None and best_thresh is None:\n",
        "            return Tree(value=np.argmax(y))\n",
        "        \n",
        "        # grow the children that result from the split\n",
        "        left_idxs = X[:, best_feat] < best_thresh\n",
        "        right_idxs = X[:, best_feat] >= best_thresh\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
        "        self.importance[best_feat] +=1\n",
        "\n",
        "        return Tree(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_criteria(self, X, y, feat_idxs):\n",
        "        best_feature = None\n",
        "        best_thresh = None\n",
        "        best_gain = 0\n",
        "\n",
        "        # for i in range(feat_idxs):\n",
        "        for i in feat_idxs:\n",
        "            # all the examples but only ith index, and don't want to check the same value twice\n",
        "            X_column = X[:, i]\n",
        "            values = np.unique(X_column)\n",
        "            for value in values:\n",
        "                left_idx = X_column < value\n",
        "                right_idx = X_column >= value\n",
        "                if len(y[left_idx]) > 0 and len(y[right_idx]) > 0:\n",
        "                    parent_entropy = self.criterion(y)\n",
        "                    n = len(y)\n",
        "                    n_l, n_r = len(y[left_idx]), len(y[right_idx])\n",
        "                    e_l, e_r = self.criterion(y[left_idx]), self.criterion(y[right_idx])\n",
        "                    child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
        "                    gain = parent_entropy - child_entropy\n",
        "                    if gain > best_gain:\n",
        "                        best_gain = gain\n",
        "                        best_feature = i\n",
        "                        best_thresh = value\n",
        "\n",
        "        return best_feature, best_thresh\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        unique_labels, counts = np.unique(y, return_counts=True)\n",
        "        most_common_idx = np.argmax(counts)\n",
        "        most_common_label = unique_labels[most_common_idx]\n",
        "        return most_common_label\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] < node.threshold:\n",
        "            return self._traverse_tree(x, node.left)\n",
        "        return self._traverse_tree(x, node.right)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BE8wu0MGN_H-"
      },
      "outputs": [],
      "source": [
        "class RandomForest():\n",
        "    \"\"\"\n",
        "        You can add/change any variables/methods to meet your need.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None):\n",
        "        \n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.boostrap = boostrap\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "\n",
        "    def bootstrap_sample(self, X, y ):\n",
        "        n_samples = X.shape[0]\n",
        "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X[idxs], y[idxs]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        self.max_features = X.shape[1] if not self.max_features else min(int(self.max_features), X.shape[1])\n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTree(max_depth=self.max_depth, max_features=self.max_features, criterion=self.criterion)\n",
        "            if self.boostrap:\n",
        "                X_samp, y_samp = self.bootstrap_sample(X, y)\n",
        "            else:\n",
        "                X_samp, y_samp = X, y\n",
        "            tree.fit(X_samp, y_samp)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        unique_labels, counts = np.unique(y, return_counts=True)\n",
        "        most_common_idx = np.argmax(counts)\n",
        "        most_common_label = unique_labels[most_common_idx]\n",
        "        return most_common_label\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
        "        y_pred = [self._most_common_label(tree_pred) for tree_pred in tree_preds]\n",
        "        return np.array(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPUsaCh2T9Fs"
      },
      "source": [
        "# Questions for Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zSB-Uqp4OaaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['+' '+' '+' '+' '+' '-']: entropy = 0.6500224216483541\n",
            "['+' '+' '+' '-' '-' '-']: entropy = 1.0\n",
            "['+' '-' '-' '-' '-' '-']: entropy = 0.6500224216483541\n",
            "\n",
            "['+' '+' '+' '+' '+' '-']: gini index = 0.2777777777777777\n",
            "['+' '+' '+' '-' '-' '-']: gini index = 0.5\n",
            "['+' '-' '-' '-' '-' '-']: gini index = 0.2777777777777777\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For Q1\n",
        "ex1 = np.array([\"+\", \"+\", \"+\", \"+\", \"+\", \"-\"])\n",
        "ex2 = np.array([\"+\", \"+\", \"+\", \"-\", \"-\", \"-\"])\n",
        "ex3 = np.array([\"+\" ,\"-\", \"-\", \"-\", \"-\", \"-\"])\n",
        "\n",
        "print(f\"{ex1}: entropy = {entropy(ex1)}\\n{ex2}: entropy = {entropy(ex2)}\\n{ex3}: entropy = {entropy(ex3)}\\n\")\n",
        "print(f\"{ex1}: gini index = {gini(ex1)}\\n{ex2}: gini index = {gini(ex2)}\\n{ex3}: gini index = {gini(ex3)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G_t9N9fnOdon"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2-1 max_depth=3:  0.7325\n"
          ]
        }
      ],
      "source": [
        "# For Q2-1, validation accuracy should be higher than or equal to 0.73\n",
        "\n",
        "np.random.seed(0) # You may adjust the seed number in all the cells\n",
        "\n",
        "dt_depth3 = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
        "dt_depth3.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "acc = accuracy_score(y_val, dt_depth3.predict(X_val))\n",
        "\n",
        "print(\"Q2-1 max_depth=3: \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T0HcgzMdjHRP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n    Updated as of 20:30 on Apr. 22.\\n    The accuracy assertion has been removed. However, you can still use Sklearn's accuracy metric to evaluate the correctness of your implementation.\\n\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Updated as of 20:30 on Apr. 22.\n",
        "    The accuracy assertion has been removed. However, you can still use Sklearn's accuracy metric to evaluate the correctness of your implementation.\n",
        "\"\"\"\n",
        "\n",
        "# \"\"\" Do Not Modify Below \"\"\"\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier as SK_DecisionTreeClassifier\n",
        "\n",
        "# sk_dt = SK_DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
        "# sk_dt.fit(X_train, y_train)\n",
        "# sk_acc = accuracy_score(y_val, sk_dt.predict(X_val))\n",
        "\n",
        "# assert round(acc, 3) == round(sk_acc, 3), \"Because the Decision Tree without any trick has a fixed answer, your accuracy should be the same as sklearn, otherwise your implementation might have some problems\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SjCPMr-eQ7jn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2-2 max_depth=10:  0.8525\n"
          ]
        }
      ],
      "source": [
        "# For Q2-2, validation accuracy should be higher than or equal to 0.85\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_depth10 = DecisionTree(criterion='gini', max_features=None, max_depth=10)\n",
        "dt_depth10.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q2-2 max_depth=10: \", accuracy_score(y_val,  dt_depth10.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iTbxGPrbO2jT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3-1 criterion='gini':  0.7325\n"
          ]
        }
      ],
      "source": [
        "# For Q3-1, validation accuracy should be higher than or equal to 0.73\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_gini = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
        "dt_gini.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q3-1 criterion='gini': \", accuracy_score(y_val, dt_gini.predict(X_val)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1XG7eAKUQ-YU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3-2 criterion='entropy':  0.77\n"
          ]
        }
      ],
      "source": [
        "# For Q3-2, validation accuracy should be higher than or equal to 0.77\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "dt_entropy = DecisionTree(criterion='entropy', max_features=None, max_depth=3)\n",
        "dt_entropy.fit(X_train, y_train, sample_weight=None)\n",
        "\n",
        "print(\"Q3-2 criterion='entropy': \", accuracy_score(y_val, dt_entropy.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "joE89xabPsXg"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For Q4\n",
        "\n",
        "# Use simply counting to get the feature importance: dt_depth10.importance\n",
        "\n",
        "labelList=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']\n",
        "\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(labelList,dt_depth10.importance.values())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg97qz_xUGfP"
      },
      "source": [
        "# Questions for Random Rorest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SlrdIW1ERJ8F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q6-1 n_estimators=10:  0.88625\n"
          ]
        }
      ],
      "source": [
        "# For Q5-1, validation accuracy should be higher than or equal to 0.88\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_estimators10 = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_estimators10.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q6-1 n_estimators=10: \", accuracy_score(y_val, rf_estimators10.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4qcLuIkbRUfM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q6-1 n_estimators=50:  0.89625\n"
          ]
        }
      ],
      "source": [
        "# For Q5-2, validation accuracy should be higher than or equal to 0.89\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_estimators50 = RandomForest(n_estimators=50, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_estimators50.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q6-1 n_estimators=50: \", accuracy_score(y_val, rf_estimators50.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n-DbniYhRYmM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q7-1 max_features='sqrt':  0.88625\n"
          ]
        }
      ],
      "source": [
        "# For Q6-1, validation accuracy should be higher than or equal to 0.88\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_maxfeature_sqrt = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_maxfeature_sqrt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q7-1 max_features='sqrt': \", accuracy_score(y_val,  rf_maxfeature_sqrt.predict(X_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PF9yufSaRffn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q7-1 max_features='All':  0.86625\n"
          ]
        }
      ],
      "source": [
        "# For Q6-2, validation accuracy should be higher than or equal to 0.86\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "rf_maxfeature_none = RandomForest(n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
        "rf_maxfeature_none.fit(X_train, y_train)\n",
        "\n",
        "print(\"Q7-1 max_features='All': \", accuracy_score(y_val, rf_maxfeature_none.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjopdAZqUKbF"
      },
      "source": [
        "# Train your own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def poly_expand(dataframe):\n",
        "    dataframe['Feature1*50']=dataframe['Feature1']*50\n",
        "    dataframe['Feature2*50']=dataframe['Feature1']*50\n",
        "    dataframe['Feature1^2']=dataframe['Feature1']**2\n",
        "    dataframe['Feature1 Feature2']=dataframe['Feature1']*dataframe['Feature2']\n",
        "    dataframe['Feature1 Feature3']=dataframe['Feature1']*dataframe['Feature3']\n",
        "    # dataframe['Feature1 Feature4']=dataframe['Feature1']*dataframe['Feature4']\n",
        "    dataframe['Feature1 Feature5']=dataframe['Feature1']*dataframe['Feature5']\n",
        "    dataframe['Feature1 Feature6']=dataframe['Feature1']*dataframe['Feature6']\n",
        "    # dataframe['Feature1 Feature7']=dataframe['Feature1']*dataframe['Feature7']\n",
        "    dataframe['Feature2^2']=dataframe['Feature2']**2\n",
        "    dataframe['Feature2 Feature3']=dataframe['Feature2']*dataframe['Feature3']\n",
        "    # dataframe['Feature2 Feature4']=dataframe['Feature2']*dataframe['Feature4']\n",
        "    dataframe['Feature2 Feature5']=dataframe['Feature2']*dataframe['Feature5']\n",
        "    dataframe['Feature2 Feature6']=dataframe['Feature2']*dataframe['Feature6']\n",
        "    # dataframe['Feature2 Feature7']=dataframe['Feature2']*dataframe['Feature7']\n",
        "    dataframe['Feature3^2']=dataframe['Feature3']**2\n",
        "    # dataframe['Feature3 Feature4']=dataframe['Feature3']*dataframe['Feature4']\n",
        "    dataframe['Feature3 Feature5']=dataframe['Feature3']*dataframe['Feature5']\n",
        "    dataframe['Feature3 Feature6']=dataframe['Feature3']*dataframe['Feature6']\n",
        "    # dataframe['Feature3 Feature7']=dataframe['Feature3']*dataframe['Feature7']\n",
        "    # dataframe['Feature4^2']=dataframe['Feature4']**2\n",
        "    # dataframe['Feature4 Feature5']=dataframe['Feature4']*dataframe['Feature5']\n",
        "    # dataframe['Feature4 Feature6']=dataframe['Feature4']*dataframe['Feature6']\n",
        "    # dataframe['Feature4 Feature7']=dataframe['Feature4']*dataframe['Feature7']\n",
        "    dataframe['Feature5^2']=dataframe['Feature5']**2\n",
        "    dataframe['Feature5 Feature6']=dataframe['Feature5']*dataframe['Feature6']\n",
        "    # dataframe['Feature5 Feature7']=dataframe['Feature5']*dataframe['Feature7']\n",
        "    dataframe['Feature6^2']=dataframe['Feature6']**2\n",
        "    # dataframe['Feature6 Feature7']=dataframe['Feature6']*dataframe['Feature7']\n",
        "    # dataframe['Feature7^2']=dataframe['Feature7']**2\n",
        "    return dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
        "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
        "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
        "\n",
        "X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']]\n",
        "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']]\n",
        "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']]\n",
        "\n",
        "X_train = poly_expand(X_train).to_numpy()\n",
        "y_train = df_train[\"Target\"].to_numpy()\n",
        "\n",
        "X_val = poly_expand(X_val).to_numpy()\n",
        "y_val = df_val[\"Target\"].to_numpy()\n",
        "\n",
        "X_test = poly_expand(X_test).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(800, 24)\n",
            "(800,)\n",
            "(800, 24)\n",
            "(800,)\n",
            "(800, 24)\n",
            "(800,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "# np.random.seed(2)\n",
        "# acc=0\n",
        "# record=0\n",
        "# for i in range(1,300,10):\n",
        "#     rf_maxfeature_none = RandomForest(n_estimators=i, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
        "#     rf_maxfeature_none.fit(X_train, y_train)\n",
        "#     accuracy=accuracy_score(y_val, rf_maxfeature_none.predict(X_val))\n",
        "#     if accuracy > acc:\n",
        "#         acc=accuracy\n",
        "#         record=i\n",
        "# print(\"highest acc: \",acc)\n",
        "   \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimators: 200 , acc:  0.89875\n",
            "Best renew :  200  , acc:  0.89875\n",
            "Estimators: 220 , acc:  0.9\n",
            "Best renew :  220  , acc:  0.9\n",
            "Estimators: 240 , acc:  0.90125\n",
            "Best renew :  240  , acc:  0.90125\n",
            "Estimators: 260 , acc:  0.9\n",
            "Estimators: 280 , acc:  0.90125\n",
            "Estimators: 300 , acc:  0.90125\n",
            "Estimators: 320 , acc:  0.90125\n",
            "Estimators: 340 , acc:  0.9\n",
            "Estimators: 360 , acc:  0.90125\n",
            "Estimators: 380 , acc:  0.90125\n",
            "Estimators: 400 , acc:  0.90125\n",
            "Estimators: 420 , acc:  0.90125\n",
            "Estimators: 440 , acc:  0.9025\n",
            "Best renew :  440  , acc:  0.9025\n",
            "Estimators: 460 , acc:  0.90125\n",
            "Estimators: 480 , acc:  0.90125\n",
            "Estimators: 500 , acc:  0.9\n",
            "Estimators: 520 , acc:  0.90125\n",
            "Estimators: 540 , acc:  0.90125\n",
            "Estimators: 560 , acc:  0.90375\n",
            "Best renew :  560  , acc:  0.90375\n",
            "Estimators: 580 , acc:  0.9025\n",
            "highest acc:  0.90375  with estimators= 560\n"
          ]
        }
      ],
      "source": [
        "acc=0\n",
        "record=0\n",
        "for i in range(200,600,20):\n",
        "    np.random.seed(2)\n",
        "    own_model = RandomForest(n_estimators=i, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "    own_model.fit(X_train, y_train)\n",
        "    accuracy=accuracy_score(y_val, own_model.predict(X_val))\n",
        "    print(\"Estimators:\" ,i ,\", acc: \",accuracy)\n",
        "    if accuracy > acc:\n",
        "        print(\"Best renew : \",i,\" , acc: \", accuracy)\n",
        "        acc=accuracy\n",
        "        record=i\n",
        "    if acc >0.90625:\n",
        "        break\n",
        "print(\"highest acc: \",acc ,\" with estimators=\",record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5cmxQjK3Rja9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best acc we get on validation set: 0.89875\n",
            "test_pred shape:  (800,)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(2)\n",
        "own_model = RandomForest(n_estimators=560,  max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
        "own_model.fit(X_train, y_train)\n",
        "accuracy=accuracy_score(y_val, own_model.predict(X_val))\n",
        "print(\"best acc we get on validation set:\",accuracy)\n",
        "test_pred = own_model.predict(X_test)\n",
        "\n",
        "print(\"test_pred shape: \", test_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "O3EUFXZW994g"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n    Updated as of 20:30 on Apr. 22.\\n    We have modified the baseline score, please check the HW3 slide.\\n'"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Updated as of 20:30 on Apr. 22.\n",
        "    We have modified the baseline score, please check the HW3 slide.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "XCaZ4yFuR34B"
      },
      "outputs": [],
      "source": [
        "# output csv\n",
        "df_test = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
        "df_test[\"Target\"] = test_pred\n",
        "df_test.to_csv(\"311552034_prediction.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "2dafc9818e2680afefcb30271426368bee6f11cde5b82a7c0b85f0135f5a01d1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
